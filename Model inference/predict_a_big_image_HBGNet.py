#!/usr/bin/env python
# coding: utf-8
import cv2
from pathlib import Path
import torch
import torch.backends.cudnn
from torch.utils.data import DataLoader, Dataset
from torch.autograd import Variable
from torchvision import transforms
from HBGNet import Field
from skimage import morphology
import numpy as np
import shutil
from tqdm import tqdm
import os
from skimage import io
import warnings
from osgeo import gdal

warnings.filterwarnings("ignore")
# 设置GDAL环境变量以使用所有CPU
gdal.SetConfigOption('GDAL_NUM_THREADS', 'ALL_CPUS')

def readTif(fileName, xoff = 0, yoff = 0, data_width = 0, data_height = 0):
    dataset = gdal.Open(fileName)
    if dataset == None:
        print(fileName + "文件无法打开")
    #  栅格矩阵的列数
    width = dataset.RasterXSize
    #  栅格矩阵的行数
    height = dataset.RasterYSize
    #  波段数
    bands_number = dataset.RasterCount
    # #  获取数据
    # if(data_width == 0 and data_height == 0):
    #     data_width = width
    #     data_height = height
    # data = dataset.ReadAsArray(xoff, yoff, data_width, data_height)
    #  获取仿射矩阵信息
    geotrans = dataset.GetGeoTransform()
    #  获取投影信息
    proj = dataset.GetProjection()
    return width, height, bands_number, dataset, geotrans, proj

def writeTiff(im_data, im_geotrans, im_proj, path):
    if 'int8' in im_data.dtype.name:
        datatype = gdal.GDT_Byte
    elif 'int16' in im_data.dtype.name:
        datatype = gdal.GDT_UInt16
    else:
        datatype = gdal.GDT_Float32
    if len(im_data.shape) == 3:
        im_bands, im_height, im_width = im_data.shape
    else:
          im_bands, (im_height, im_width) = 1, im_data.shape
        # im_data = np.array([im_data])
        # im_bands, im_height, im_width = im_data.shape
    # 创建文件
    driver = gdal.GetDriverByName("GTiff")
    dataset = driver.Create(path, int(im_width), int(im_height), int(im_bands), datatype)
    if (dataset != None):
        dataset.SetGeoTransform(im_geotrans)  # 写入仿射变换参数
        dataset.SetProjection(im_proj)  # 写入投影
    if im_bands == 1:
      dataset.GetRasterBand(1).WriteArray(im_data)
    else:
        for i in range(im_bands):
           dataset.GetRasterBand(i + 1).WriteArray(im_data[i])
    del dataset

# 根据填补的大小截取图片
def redundancy_crop(img, i, j, targetSize, padding_size):
    if len(img.shape) > 2:
        temp_img = img[i * targetSize:i * targetSize + targetSize + 2 * padding_size,
                   j * targetSize:j * targetSize + targetSize + 2 * padding_size, :]
    else:
        temp_img = img[i * targetSize:i * targetSize + targetSize + 2 * padding_size,
                   j * targetSize:j * targetSize + targetSize + 2 * padding_size]
    return temp_img

# 将图片截取为原始大小（未填充）
def redundancy_crop2(img, padding_size):
    h = img.shape[0]
    w = img.shape[1]
    temp_img = img[padding_size:h - padding_size, padding_size:w - padding_size]
    return temp_img

class DatasetImage(Dataset):

    def __init__(self, dir):
        self.file_names = os.listdir(dir)
        self.dir = dir

    def __len__(self):
        return len(self.file_names)

    def __getitem__(self, idx):
        img_file_name = self.file_names[idx]
        # todo 注意不同的数据类型有不同的处理方式
        # image = load_image(os.path.join(self.dir, img_file_name))
        image = load_image_gdal(os.path.join(self.dir, img_file_name))

        return img_file_name, image

def load_image_gdal(path):
    # 打开遥感影像文件
    dataset = gdal.Open(path)
    if dataset is None:
        raise FileNotFoundError(f"无法打开文件：{path}")

    # 读取各个波段的数据,读取前三个波段
    bands = []
    for i in range(1, 4):
        band = dataset.GetRasterBand(i).ReadAsArray().astype(np.float32)
        bands.append(band)

    # 堆叠波段数据，形状为 (3, 高度, 宽度)
    img_data = np.stack(bands, axis=0)
    img_data = img_data.astype(float)

    # 转换为 PyTorch 张量
    img_data = torch.from_numpy(img_data)

    # 定义数据预处理步骤
    data_transforms = transforms.Compose([
        # UKR_2023
        transforms.Normalize([675.6458129882812, 656.1358642578125, 447.96978759765625], [264.444580078125, 167.1501922607422, 138.0218505859375])
    ])

    # 对图像进行预处理
    img_data = data_transforms(img_data)

    return img_data

def get_dataset_loaders():
    batch_size = 1
    test_dataset = DatasetImage(
        "./temp_pic",
    )

    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=0)
    return test_loader

def mkdir(path):
    if not os.path.exists(path):
        os.mkdir(path)

def input_and_output(img_data, model, crop_size, padding_size, loader=None, generate_data=True):
    """
    args:
        pic_path : the picture you want to predict
        model    : the model you want to predict
    note:
        step one : generate some pictures from one picture
        step two : predict from the images generated by step one
    """
    # 切片大小
    image_size = crop_size

    data = img_data
    # 转换为 (x, x, 3)
    data = data.transpose(1, 2, 0)

    raw_h, raw_w = data.shape[:2]

    # 填充，避免出现边界效应
    b = padding_size
    # 计算可以有多少个切片，
    row = raw_h // image_size + 1
    col = raw_w // image_size + 1
    # 计算填充的大小
    radius_h = row * image_size - raw_h
    radius_w = col * image_size - raw_w
    # 对图像进行填充
    # 在 data 的下方添加 radius_h 高度的边框和在右侧添加 radius_w 宽度的边框
    data = cv2.copyMakeBorder(data, 0, radius_h, 0, radius_w, cv2.BORDER_REFLECT)

    # TODO: 这里要注意是否要填充32像素
    data = cv2.copyMakeBorder(data, b, b, b, b, cv2.BORDER_REFLECT)
    # print("数据的最大值为：", np.max(data))

    data = np.array(data)
    # 创建结果容器
    mask_whole = np.zeros((row * image_size, col * image_size), dtype=np.uint8)
    # mask_whole = np.zeros((row * image_size, col * image_size), dtype=np.float32) #当预测距离dist的时候用这个

    # 如果不需要生成数据，那么进行模型的预测，输入模型的是经过切片和填充的图片
    if generate_data == False:
        print('开始预测')
        result = []
        #  读取 temp_pic 文件夹下的所有文件
        for batch in tqdm(loader):
            # 进行模型评估
            net = model
            net.eval()

            # images = batch['img'].to(device, dtype=torch.float)
            img_file_name, inputs = batch
            images = Variable(inputs.to(device, dtype=torch.float))
            # h, w = images.shape[2:]
            # new_h = int(h * scale_size)
            # images = F.interpolate(images, size=(new_h, new_h), mode='bilinear')

            outputs1, outputs2, outputs3 = net(images)
            outputs4, outputs5, outputs6 = net(torch.flip(images, [-1]))
            predict_2 = torch.flip(outputs4, [-1])
            outputs7, outputs8, outputs9 = net(torch.flip(images, [-2]))
            predict_3 = torch.flip(outputs7, [-2])
            outputs10, outputs11, outputs12 = net(torch.flip(images, [-1, -2]))
            predict_4 = torch.flip(outputs10, [-1, -2])

            predict_list = outputs1 + predict_2 + predict_3 + predict_4

            pred = predict_list / 4.
            pred = torch.sigmoid(pred)
            outputs1 = pred.detach().cpu().numpy().squeeze()

            res = np.zeros((256, 256))
            res[outputs1 > 0.5] = 255
            res[outputs1 <= 0.5] = 0
            res = morphology.remove_small_objects(res.astype(int), 1000)
            res = np.array(res, dtype='uint8')

            result.append(res)
        directdory_path = Path('temp_pic')
        map_list = [str(i.name) for i in directdory_path.iterdir() if i.is_file()]


    for i in range(row):
        for j in range(col):
            if generate_data:
                # 先裁剪数据保存下来
                crop_img = redundancy_crop(data, i, j, image_size, padding_size)
                ch, cw, _ = crop_img.shape
                # TODO 注意这里要根据数据类型来选择保存方式
                # 16位数据改为np.uint16显示正常，这是缺失了投影信息。
                io.imsave(f'temp_pic/{i}_{j}.tif', crop_img.astype(np.uint16))  # 这个位置因为是4波段 我就保持和之前训练的数据类型一致  uint16  8
                # cv2.imwrite(f'temp_pic/{i}_{j}.tif', crop_img)
            else:
                # 根据map_list找到对应的图片
                temp = result[map_list.index(f'{i}_{j}.tif')]
                # 截取图片
                temp = redundancy_crop2(temp, padding_size)
                # 将图片放入结果容器
                mask_whole[i * image_size:i * image_size + image_size,
                j * image_size:j * image_size + image_size] = temp
    del data
    # 去掉填充，恢复到原始大小，返回结果
    return mask_whole[:raw_h, :raw_w]

def predict_seg(big_image_path, model_path, crop_size, padding_size, save_path):


    # predict on more model
    print('加载模型·······')
    # 加载模型
    # 加载模型
    net = Field(num_classes=2)
    net = net.to(device)

    # 加载模型权重
    net.load_state_dict(torch.load(model_path))

    # 加载数据
    im_width, im_height, bands_number, dataset, im_geotrans, im_proj = readTif(big_image_path)
    print("读取影像数据成功。")

    # 保存处理后的栅格数据
    # 创建输出栅格数据集
    driver = gdal.GetDriverByName('GTiff')
    output_ds = driver.Create(save_path,  # 输出栅格数据集路径
                              im_width,  # 输出栅格数据集的宽度
                              im_height,  # 输出栅格数据集的高度
                              1,  # 波段数
                              # dataset.GetRasterBand(1).DataType,  # 数据类型
	                          gdal.GDT_Byte,  # 数据类型
                              options=['COMPRESS=LZW', 'PREDICTOR=2',  # 创建选项
                                       'BIGTIFF=YES', "TILED=YES",
                                       'NUM_THREADS=ALL_CPUS']
                              )
    # 设置地理变换参数和投影信息
    output_ds.SetGeoTransform(im_geotrans)
    output_ds.SetProjection(im_proj)

    # 设置无数据值
    output_ds.GetRasterBand(1).SetNoDataValue(0)  # 设置0为无数据值

    # todo 设置合适的块大小
    block_xsize = 10240  # 可以根据实际情况调整
    block_ysize = 10240  # 可以根据实际情况调整

    # 获取栅格的大小
    xsize = im_width
    ysize = im_height

    # 计算总的块数以设置进度条的总步数
    total_blocks = ((xsize + block_xsize - 1) // block_xsize) * ((ysize + block_ysize - 1) // block_ysize)

    # 逐块读取、处理和写入数据
    with tqdm(total=total_blocks, desc="Processing Blocks") as pbar:
        for y in range(0, ysize, block_ysize):
            if y + block_ysize > ysize:
                read_ysize = ysize - y
            else:
                read_ysize = block_ysize

            for x in range(0, xsize, block_xsize):
                if x + block_xsize > xsize:
                    read_xsize = xsize - x
                else:
                    read_xsize = block_xsize

                # 创建缓存文件夹
                if not os.path.exists('temp_pic'):
                    os.makedirs('temp_pic')

                # 读取当前块的影像数据
                raster_array = dataset.ReadAsArray(x, y, read_xsize, read_ysize)

                # 将该影像作为预测的输入
                # 第一步，对每一张大图进行遍历，生成用于预测的小图,将图片保存在temp_pic文件夹下
                input_and_output(raster_array, net, crop_size, padding_size, generate_data=True)

                # 第二步，将分割好的小图进行预测，预测结果合并
                name = os.path.split(big_image_path)[-1].split(".")[0]
                test_loader = get_dataset_loaders()
                # 预测
                mask_result = input_and_output(raster_array, net, crop_size, padding_size, loader=test_loader,
                                               generate_data=False)
                # mask_result = image_normalization(mask_result, 0, 1)
                # mask_result = mask_result > 0.12

                mask_result = mask_result.astype(np.uint8) * 255

                # 写入数据块到输出文件
                output_ds.GetRasterBand(1).WriteArray(mask_result, x, y)

                # 递归删除文件夹
                try:
                    shutil.rmtree('temp_pic')
                except:
                    pass
                pbar.update(1)

                # 释放内存
                del raster_array


if __name__ == '__main__':

    device = 'cuda:0'
    dark = [0, 0, 0]

    # 切片大小
    crop_size = 256
    padding_size = 0       # 切片镜像延展大小

    # 数据路径，用于存放到分割的大图。
    big_image_path = r"/home/lijb/data/Predict_big_image/Big_Image/s2_2023_1_12_month_month_UKR_mosaic.tif"
    model_path = r"/home/lijb/data/Project/HBGNet_improve/UKR_2023/best.pt"
    save_path = r"/home/lijb/data/Predict_big_image/Parcel_Result/UKR_Parcel/UKR_parcel_result_2023_HBGNet.tif"

    predict_seg(big_image_path, model_path, crop_size, padding_size, save_path)
